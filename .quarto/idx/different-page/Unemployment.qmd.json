{"title":"**Kansas Unemployment During COVID-19**","markdown":{"yaml":{"toc":false,"author":"Nigel Soria","badges":true,"categories":["labor statistics","unemployment rate","essential worker","work context"],"permalink":"/unemployment-calc/","image":"images/ks-unemp.png"},"headingText":"**Kansas Unemployment During COVID-19**","containsRefs":false,"markdown":"\n\n\n# **Background**\n\nMany businesses are experiencing large decreases in sales and revenue as a result of state and local stay-at-home orders associated with the COVID-19 pandemic, and these businesses are already responding to potential solvency and liquidity problems by laying off workers. Accordingly, many are wondering how high the unemployment rate might be in the second quarter of 2020.\n\nNot all businesses, sectors, or occupations will experience the negative shock from COVID-19 equally. Many workers, such as those in professional services, may be able to work from home and continue their activities with minimal disruption. Other workers, such as those who work in occupations that involve direct physical contact with customers (e.g., barbers and hairstylists), are likely to see their jobs negatively affected by social-distancing measures and stay-at-home orders.\n\nIn this post, I use Kansas-specific data on occupation composition to replicate [recent analysis](https://www.stlouisfed.org/on-the-economy/2020/march/back-envelope-estimates-next-quarters-unemployment-rate \"Back-of-the-Envelope Estimates of Next Quarter’s Unemployment Rate\") by the St. Louis Fed, which attempts to arrive at an estimate of what the unemployment rate may look like at the end of the second quarter of 2020. The St. Louis Fed estimates a 32.1 percent unemployment rate for the second quarter of 2020.\n\n### **Current Labor Statistics**\n\nI start with the state of the Kansas economy as of February 2020. According to the Kansas Department of Labor (via [KLIC](https://klic.dol.ks.gov/vosnet/Default.aspx)), the civilian labor force consisted of approxiately 1.5 million people, and the seasonally-adjusted unemployment rate was 3.1%, which means there were around 46,000 unemployed Kansans in February. In the calculations that follow, I assumed the labor force remains constant and that none of the currently unemployed individuals would be able to find a job in the second quarter of 2020.\n\n```{python}\n#| hidden: true\nimport numpy as np\nimport pandas as pd\nimport requests\nimport scipy.stats as ss\nimport matplotlib as mpl\nimport json\nimport plotly.graph_objects as go\nfrom urllib.request import urlopen\nfrom IPython.display import Image\nfrom IPython.display import HTML\n\n```\n\n```{python}\n#| echo: false\n# feb 2020 labor force and unemployment rate from KDOL\nlf_feb20 = 1496507.0\nunemp_feb20 = 0.031\n\nprint('Current labor statistics from the Kansas Department of Labor (February 2020):')\nprint('Civilian Labor Force = {l:,.0f}'.format(l=lf_feb20))\nprint('Unemployment Rate = {r:0.1f}%'.format(r=unemp_feb20*100))\n```\n\n# **Methodology**\n\nTo estimate the Kansas unemployment rate for the second quarter of 2020, I follow the analysis by the St. Louis Fed and combine occupation composition data from the Bureau of Labor Statistics with work context data from O\\*Net Online to compute how many jobs might be exposed to layoff risk due to social distancing measures and stay-at-home orders.\n\nIn a [recent article](https://www.stlouisfed.org/on-the-economy/2020/march/social-distancing-contact-intensive-occupations \"Social Distancing and Contact-Intensive Occupations\"), Matthew Famiglietti, Fernando Leibovici and Ana Maria Santacreu combine individual-level data from the 2017 American Community Survey with information on occupational contact intensity from O\\*NET to determine how many people work in occupations that require the worker to perform tasks in close physical proximity to other people. They find that 27.3 million workers have occupations with a high contact intensity. These occupations include barbers, hairstylists, food and beverage serving workers, and flight attendants, among others.\n\nIn [another article](https://www.stlouisfed.org/on-the-economy/2020/march/covid-19-workers-highest-unemployment-risk \"COVID-19: Which Workers Face the Highest Unemployment Risk?\"), Charles Gascon uses Occupation Employment Statistics from the Bureau of Labor Statistics to determine which occupations face a high risk of unemployment, and he estimates that 46 percent, or approximately 67 million U.S. workers, face a high risk of being laid off.\n\nI combine the approaches from the two articles and merge state-level occupation composition data from the Bureau of Labor Statics with information on occupational contact intensity from O\\*NET. I saved some time by extracting the contact intensity information from the Famiglietti, Leibovici, and Santacreu dataset as it is publicly available.\n\n```{python}\n#| echo: false\n\n#libraries\nimport pandas as pd\n\n\n# adjust pandas display options\npd.set_option('display.max_columns', None)  # show all columns\npd.set_option('display.max_rows', None)  # show all rows\npd.set_option('display.width', None)  # auto-adjust width\n\n\n# load proximity scores from Famiglietti, Leibovici, and Santacreu blog post\nnames = ['soc', 'prox_index', 'score', 'essential', 'home_work', 'category']\n\nprox = pd.read_excel(\n    'data/contact-intensive-occupations.xlsx',\n    usecols=[0,1,2,3,4,9],\n    sheet_name='Appendix', \n    names=names,\n    dtype=str\n)\n\n\n# load state-level data from the Bureau of Labor Statistics\ndata = pd.read_excel('data/state-m2019-dl.xlsx', header=0, sheet_name='State_M2019_dl', dtype=str)\n\n\n# remove non-Kansas data and rows without estimates\ndata = data[(data['area']=='20') & (data['tot_emp']!='**') & (data['o_group'].astype(str)=='detailed')]\n\ndata.head()\n#hide\n\n# The Kansas Occupation Employment Statistics data contain a column named `occ_code`, which represents the six-digit occupation code; however, the Famiglietti, Leibovici, and Santacreu data contain a four digit occupation code (and no hyphen), so we need to create a similar field in the Kansas dataset that we can use to match the Famiglietti-Leibovici-Santacreu data. \n\n```\n\nThe Kansas Occupation Employment Statistics data contain a column named \\`occ_code\\`, which represents the six-digit occupation code; however, the Famiglietti, Leibovici, and Santacreu data contain a four digit occupation code (and no hyphen), so we need to create a similar field in the Kansas dataset that we can use to match the Famiglietti-Leibovici-Santacreu data.\n\n```{python}\n#| echo: false\n\n# pull off first four digits of occ_code and remove hyphen\ndata['soc'] = data['occ_code'].str[:5]\n\ndata['soc'] = data['soc'].str.replace(r'\\D', '')\n\n\n# merge the two datasets\nmerged = pd.merge(left=data, right=prox, how='left', left_on='soc', right_on='soc')\n\nmerged.head()\n```\n\n# **Calculating the Second-Quarter Unemployment Rate**\n\nThe St. Louis Fed analysis averages the numbers from the Famiglietti-Leibovici-Santacreu and Gascon articles to arrive at a point estimate of the number of workers at risk of being laid off during the second quarter. This results in approximately 47 million people being laid off during this period. This is quite high as it assumes everyone in a \"high risk\" occupation will become laid off. Therefore, I depart from the St. Louis Fed analysis by taking into account the fact that some occupations have been designated as essential and face a lower risk of layoff. Using guidance from the [Kansas Essential Functions Framework](https://governor.kansas.gov/essential-functions-guidance/), I added a field to the Famiglietti, Leibovici, and Santacreu data that indicates whether an occupation is essential.\n\nTo calculate the expected layoffs, I added the numbers for the occupations in the highest contact intensity category (following Famiglietti, Leibovici, and Santacreu), and I subtracted the numbers from occupations that are essential (my innovation). Adding the expected layoffs to the initial number of unemployed in February results in approximately 66,000 total unemployed Kansans. Given the assumption of a constant labor force, this results in an unemployment rate of 4.4 percent. The calculation can be summarized in the following steps:\n\n```{python}\n#| echo: false\n#hide_input\n\n# summary input calculations\nunemp = lf_feb20 * unemp_feb20\n\nhigh_contact = merged[merged['score']=='2']['tot_emp'].astype(int).sum()\n\nessential = merged[(merged['score']=='2') & (merged['essential']=='1')]['tot_emp'].astype(int).sum()\n\nlayoffs = high_contact - essential\n\nest_unemp = unemp + layoffs\n\nest_rate = est_unemp / lf_feb20\n\n\n# steps to calculate estimated unemployment rate\n# print('Steps to calculate the estimated unemployment rate (using data from Method 1):')\nprint('1. Kansas civilian labor force in February 2020 = {l:,.0f} (KDOL)'.format(l=lf_feb20))\nprint('2. Kansas unemployment rate in February 2020 = {r:0.1f}% (KDOL)'.format(r=unemp_feb20*100))\nprint('3. Unemployed Kansans in February 2020 = {u:,.0f} (#1 * #2)'.format(u=unemp))\nprint('4. Kansas workers in high contact-intensive occupations = {c:,.0f} (Nigel\\'s calculations using O*Net data)'.format(c=high_contact))\n\nprint('5. Kansas workers employed in \"essential\" occupations = {e:,.0f} (Nigel\\'s calculations using KEFF guidance)'.format(e=essential))\n\nprint('6. Estimated layoffs in second quarter 2020 = {f:,.0f} (#4 - #5)'.format(f=layoffs))\n  \nprint('7. Unemployed Kansans in second quarter 2020 = {k:,.0f} (#3 + #6)'.format(k=est_unemp))\n  \nprint('8. Kansas unemployment rate in second quarter 2020 = {p:0.1f}% (#7 / #1)'.format(p=est_rate*100))\n```\n\n# **Sensitivity Analysis**\n\nThe St. Louis Fed estimate of 32.1 percent seems a bit high, but my estimate of 4.4 percent seems very low, especially given the large spike in the number unemployment insurance claims. This is because my estimate assumes everyone in an \"essential\" occupation will retain his or her job, which is probably not the case. For example, restaurants need cooks and delivery drivers, but they do not need waitstaff right now. Some waiters and waitresses may assist with deliveries, which may keep their hours from getting cut, but dishwashers may end up working fewer hours as they will be washing fewer dishes. We can look at the sensitivity of the estimated unemployment rate to different assumptions in the retention rate of essential occupations. That is, maybe restaurants will only retain 50 percent of their staff instead of 100 percent as the estimate currently assumes.\n\nThe graph below shows the calculated unemployment rate based on different retention rates for essential occupations. The estimated Kansas unemployment rate for Q2 2002 ranges from 4.4 percent to 22.7 percent, where 22.7 percent assumes no retention of essential occupations (i.e., similar to the St. Louis Fed analysis).\n\n```{python}\n#| echo: false\nimport numpy as np\nimport plotly.graph_objects as go\nimport pandas as pd\n\nlf_feb20 = 1496507.0\n\nunemp_feb20 = 0.031\nunemp = lf_feb20 * unemp_feb20\n\nhigh_contact = merged[merged['score']=='2']['tot_emp'].astype(int).sum()\n\nessential = merged[(merged['score']=='2') & (merged['essential']=='1')]['tot_emp'].astype(int).sum()\n\nlayoffs = high_contact - essential\n\nest_unemp = unemp + layoffs\n\nest_rate = est_unemp / lf_feb20\n\n# generate unemployment estimates by varying the retention rate\nrates = np.linspace(0,1,11)\n\nestimates = []\n\nfor rate in rates:\n    estimate = (unemp + (high_contact - essential*rate)) / lf_feb20 * 100\n    estimates.append(round(estimate,1))\n\n    \n# configure graph settings    \nunemp_data = go.Scatter(x=np.linspace(0,100,11), y=estimates)\n\nlayout = go.Layout(xaxis=dict(title='Retention Rate (%)'), yaxis=dict(title='Unemployment Rate (%)'))\n\nfig = go.Figure(data=[unemp_data], layout=layout)\n\nfig.update_layout(\n    title={\n        'text': 'Estimates of the Q2 2002 Kansas Unemployment Rate Under Different Retention Rates',\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\n\nfig.show()\n```\n\n# **Summary of Calculations**\n\nIt is important to note these estimates make several important assumptions:\n\n-   the calculations assume the labor force is constant and exclude the fact that some recently unemployed workers may become discouraged and cease looking for employment (i.e., no longer technically unemployed);\n\n-   many businesses may send workers home with pay, rather than laying them off;\n\n-   only occupations with a proximity score of 2 are at risk of being layed off;\n\n-   the sensitivity analysis assumes retention rates are the same accross all occupations; and\n\n-   the calculations do not account for any potential effects of fiscal measures, such as the recent stimulus package or changes in unemployment insurance policy.\n\nIt is also important to keep in mind these are rough calculations. As such, any attempts to place upper and lower bounds on these estimates would follow the same inexact process. The estimates are sensitive to a number of assumptions, but we may be able to relax some of these assumptions with better, more up-to-date data.\n\nThe expected duration of unemployment matters just as much, if not more, than the unemployment rate itself, especially if the recovery is quicker than we anticipate; however, the uncertainty around when and where it will be safe to resume certain economic activity makes *ex ante* analysis of the economic impact of COVID-19 very difficult. At best, we can look at what may happen if different scenarios unfold.\n\n# **Other Limitations and Areas for Improvement**\n\nThough I followed guidance from the Kansas Essential Functions Framework, the designation of occupations as essential is somewhat subjective. It might be nice to have others weigh in on which occupations meet the conditions of these guidelines.\n\nAlso, I started working on adding a field that indicates which positions may be performed from home (we would be able to subtract these from the unemployed as well), but this is also very subjective. I thought O\\*NET might also have some sort of \"telecommute score,\" but I haven't been able to find anything like that just yet.\n","srcMarkdownNoYaml":"\n\n# **Kansas Unemployment During COVID-19**\n\n# **Background**\n\nMany businesses are experiencing large decreases in sales and revenue as a result of state and local stay-at-home orders associated with the COVID-19 pandemic, and these businesses are already responding to potential solvency and liquidity problems by laying off workers. Accordingly, many are wondering how high the unemployment rate might be in the second quarter of 2020.\n\nNot all businesses, sectors, or occupations will experience the negative shock from COVID-19 equally. Many workers, such as those in professional services, may be able to work from home and continue their activities with minimal disruption. Other workers, such as those who work in occupations that involve direct physical contact with customers (e.g., barbers and hairstylists), are likely to see their jobs negatively affected by social-distancing measures and stay-at-home orders.\n\nIn this post, I use Kansas-specific data on occupation composition to replicate [recent analysis](https://www.stlouisfed.org/on-the-economy/2020/march/back-envelope-estimates-next-quarters-unemployment-rate \"Back-of-the-Envelope Estimates of Next Quarter’s Unemployment Rate\") by the St. Louis Fed, which attempts to arrive at an estimate of what the unemployment rate may look like at the end of the second quarter of 2020. The St. Louis Fed estimates a 32.1 percent unemployment rate for the second quarter of 2020.\n\n### **Current Labor Statistics**\n\nI start with the state of the Kansas economy as of February 2020. According to the Kansas Department of Labor (via [KLIC](https://klic.dol.ks.gov/vosnet/Default.aspx)), the civilian labor force consisted of approxiately 1.5 million people, and the seasonally-adjusted unemployment rate was 3.1%, which means there were around 46,000 unemployed Kansans in February. In the calculations that follow, I assumed the labor force remains constant and that none of the currently unemployed individuals would be able to find a job in the second quarter of 2020.\n\n```{python}\n#| hidden: true\nimport numpy as np\nimport pandas as pd\nimport requests\nimport scipy.stats as ss\nimport matplotlib as mpl\nimport json\nimport plotly.graph_objects as go\nfrom urllib.request import urlopen\nfrom IPython.display import Image\nfrom IPython.display import HTML\n\n```\n\n```{python}\n#| echo: false\n# feb 2020 labor force and unemployment rate from KDOL\nlf_feb20 = 1496507.0\nunemp_feb20 = 0.031\n\nprint('Current labor statistics from the Kansas Department of Labor (February 2020):')\nprint('Civilian Labor Force = {l:,.0f}'.format(l=lf_feb20))\nprint('Unemployment Rate = {r:0.1f}%'.format(r=unemp_feb20*100))\n```\n\n# **Methodology**\n\nTo estimate the Kansas unemployment rate for the second quarter of 2020, I follow the analysis by the St. Louis Fed and combine occupation composition data from the Bureau of Labor Statistics with work context data from O\\*Net Online to compute how many jobs might be exposed to layoff risk due to social distancing measures and stay-at-home orders.\n\nIn a [recent article](https://www.stlouisfed.org/on-the-economy/2020/march/social-distancing-contact-intensive-occupations \"Social Distancing and Contact-Intensive Occupations\"), Matthew Famiglietti, Fernando Leibovici and Ana Maria Santacreu combine individual-level data from the 2017 American Community Survey with information on occupational contact intensity from O\\*NET to determine how many people work in occupations that require the worker to perform tasks in close physical proximity to other people. They find that 27.3 million workers have occupations with a high contact intensity. These occupations include barbers, hairstylists, food and beverage serving workers, and flight attendants, among others.\n\nIn [another article](https://www.stlouisfed.org/on-the-economy/2020/march/covid-19-workers-highest-unemployment-risk \"COVID-19: Which Workers Face the Highest Unemployment Risk?\"), Charles Gascon uses Occupation Employment Statistics from the Bureau of Labor Statistics to determine which occupations face a high risk of unemployment, and he estimates that 46 percent, or approximately 67 million U.S. workers, face a high risk of being laid off.\n\nI combine the approaches from the two articles and merge state-level occupation composition data from the Bureau of Labor Statics with information on occupational contact intensity from O\\*NET. I saved some time by extracting the contact intensity information from the Famiglietti, Leibovici, and Santacreu dataset as it is publicly available.\n\n```{python}\n#| echo: false\n\n#libraries\nimport pandas as pd\n\n\n# adjust pandas display options\npd.set_option('display.max_columns', None)  # show all columns\npd.set_option('display.max_rows', None)  # show all rows\npd.set_option('display.width', None)  # auto-adjust width\n\n\n# load proximity scores from Famiglietti, Leibovici, and Santacreu blog post\nnames = ['soc', 'prox_index', 'score', 'essential', 'home_work', 'category']\n\nprox = pd.read_excel(\n    'data/contact-intensive-occupations.xlsx',\n    usecols=[0,1,2,3,4,9],\n    sheet_name='Appendix', \n    names=names,\n    dtype=str\n)\n\n\n# load state-level data from the Bureau of Labor Statistics\ndata = pd.read_excel('data/state-m2019-dl.xlsx', header=0, sheet_name='State_M2019_dl', dtype=str)\n\n\n# remove non-Kansas data and rows without estimates\ndata = data[(data['area']=='20') & (data['tot_emp']!='**') & (data['o_group'].astype(str)=='detailed')]\n\ndata.head()\n#hide\n\n# The Kansas Occupation Employment Statistics data contain a column named `occ_code`, which represents the six-digit occupation code; however, the Famiglietti, Leibovici, and Santacreu data contain a four digit occupation code (and no hyphen), so we need to create a similar field in the Kansas dataset that we can use to match the Famiglietti-Leibovici-Santacreu data. \n\n```\n\nThe Kansas Occupation Employment Statistics data contain a column named \\`occ_code\\`, which represents the six-digit occupation code; however, the Famiglietti, Leibovici, and Santacreu data contain a four digit occupation code (and no hyphen), so we need to create a similar field in the Kansas dataset that we can use to match the Famiglietti-Leibovici-Santacreu data.\n\n```{python}\n#| echo: false\n\n# pull off first four digits of occ_code and remove hyphen\ndata['soc'] = data['occ_code'].str[:5]\n\ndata['soc'] = data['soc'].str.replace(r'\\D', '')\n\n\n# merge the two datasets\nmerged = pd.merge(left=data, right=prox, how='left', left_on='soc', right_on='soc')\n\nmerged.head()\n```\n\n# **Calculating the Second-Quarter Unemployment Rate**\n\nThe St. Louis Fed analysis averages the numbers from the Famiglietti-Leibovici-Santacreu and Gascon articles to arrive at a point estimate of the number of workers at risk of being laid off during the second quarter. This results in approximately 47 million people being laid off during this period. This is quite high as it assumes everyone in a \"high risk\" occupation will become laid off. Therefore, I depart from the St. Louis Fed analysis by taking into account the fact that some occupations have been designated as essential and face a lower risk of layoff. Using guidance from the [Kansas Essential Functions Framework](https://governor.kansas.gov/essential-functions-guidance/), I added a field to the Famiglietti, Leibovici, and Santacreu data that indicates whether an occupation is essential.\n\nTo calculate the expected layoffs, I added the numbers for the occupations in the highest contact intensity category (following Famiglietti, Leibovici, and Santacreu), and I subtracted the numbers from occupations that are essential (my innovation). Adding the expected layoffs to the initial number of unemployed in February results in approximately 66,000 total unemployed Kansans. Given the assumption of a constant labor force, this results in an unemployment rate of 4.4 percent. The calculation can be summarized in the following steps:\n\n```{python}\n#| echo: false\n#hide_input\n\n# summary input calculations\nunemp = lf_feb20 * unemp_feb20\n\nhigh_contact = merged[merged['score']=='2']['tot_emp'].astype(int).sum()\n\nessential = merged[(merged['score']=='2') & (merged['essential']=='1')]['tot_emp'].astype(int).sum()\n\nlayoffs = high_contact - essential\n\nest_unemp = unemp + layoffs\n\nest_rate = est_unemp / lf_feb20\n\n\n# steps to calculate estimated unemployment rate\n# print('Steps to calculate the estimated unemployment rate (using data from Method 1):')\nprint('1. Kansas civilian labor force in February 2020 = {l:,.0f} (KDOL)'.format(l=lf_feb20))\nprint('2. Kansas unemployment rate in February 2020 = {r:0.1f}% (KDOL)'.format(r=unemp_feb20*100))\nprint('3. Unemployed Kansans in February 2020 = {u:,.0f} (#1 * #2)'.format(u=unemp))\nprint('4. Kansas workers in high contact-intensive occupations = {c:,.0f} (Nigel\\'s calculations using O*Net data)'.format(c=high_contact))\n\nprint('5. Kansas workers employed in \"essential\" occupations = {e:,.0f} (Nigel\\'s calculations using KEFF guidance)'.format(e=essential))\n\nprint('6. Estimated layoffs in second quarter 2020 = {f:,.0f} (#4 - #5)'.format(f=layoffs))\n  \nprint('7. Unemployed Kansans in second quarter 2020 = {k:,.0f} (#3 + #6)'.format(k=est_unemp))\n  \nprint('8. Kansas unemployment rate in second quarter 2020 = {p:0.1f}% (#7 / #1)'.format(p=est_rate*100))\n```\n\n# **Sensitivity Analysis**\n\nThe St. Louis Fed estimate of 32.1 percent seems a bit high, but my estimate of 4.4 percent seems very low, especially given the large spike in the number unemployment insurance claims. This is because my estimate assumes everyone in an \"essential\" occupation will retain his or her job, which is probably not the case. For example, restaurants need cooks and delivery drivers, but they do not need waitstaff right now. Some waiters and waitresses may assist with deliveries, which may keep their hours from getting cut, but dishwashers may end up working fewer hours as they will be washing fewer dishes. We can look at the sensitivity of the estimated unemployment rate to different assumptions in the retention rate of essential occupations. That is, maybe restaurants will only retain 50 percent of their staff instead of 100 percent as the estimate currently assumes.\n\nThe graph below shows the calculated unemployment rate based on different retention rates for essential occupations. The estimated Kansas unemployment rate for Q2 2002 ranges from 4.4 percent to 22.7 percent, where 22.7 percent assumes no retention of essential occupations (i.e., similar to the St. Louis Fed analysis).\n\n```{python}\n#| echo: false\nimport numpy as np\nimport plotly.graph_objects as go\nimport pandas as pd\n\nlf_feb20 = 1496507.0\n\nunemp_feb20 = 0.031\nunemp = lf_feb20 * unemp_feb20\n\nhigh_contact = merged[merged['score']=='2']['tot_emp'].astype(int).sum()\n\nessential = merged[(merged['score']=='2') & (merged['essential']=='1')]['tot_emp'].astype(int).sum()\n\nlayoffs = high_contact - essential\n\nest_unemp = unemp + layoffs\n\nest_rate = est_unemp / lf_feb20\n\n# generate unemployment estimates by varying the retention rate\nrates = np.linspace(0,1,11)\n\nestimates = []\n\nfor rate in rates:\n    estimate = (unemp + (high_contact - essential*rate)) / lf_feb20 * 100\n    estimates.append(round(estimate,1))\n\n    \n# configure graph settings    \nunemp_data = go.Scatter(x=np.linspace(0,100,11), y=estimates)\n\nlayout = go.Layout(xaxis=dict(title='Retention Rate (%)'), yaxis=dict(title='Unemployment Rate (%)'))\n\nfig = go.Figure(data=[unemp_data], layout=layout)\n\nfig.update_layout(\n    title={\n        'text': 'Estimates of the Q2 2002 Kansas Unemployment Rate Under Different Retention Rates',\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\n\nfig.show()\n```\n\n# **Summary of Calculations**\n\nIt is important to note these estimates make several important assumptions:\n\n-   the calculations assume the labor force is constant and exclude the fact that some recently unemployed workers may become discouraged and cease looking for employment (i.e., no longer technically unemployed);\n\n-   many businesses may send workers home with pay, rather than laying them off;\n\n-   only occupations with a proximity score of 2 are at risk of being layed off;\n\n-   the sensitivity analysis assumes retention rates are the same accross all occupations; and\n\n-   the calculations do not account for any potential effects of fiscal measures, such as the recent stimulus package or changes in unemployment insurance policy.\n\nIt is also important to keep in mind these are rough calculations. As such, any attempts to place upper and lower bounds on these estimates would follow the same inexact process. The estimates are sensitive to a number of assumptions, but we may be able to relax some of these assumptions with better, more up-to-date data.\n\nThe expected duration of unemployment matters just as much, if not more, than the unemployment rate itself, especially if the recovery is quicker than we anticipate; however, the uncertainty around when and where it will be safe to resume certain economic activity makes *ex ante* analysis of the economic impact of COVID-19 very difficult. At best, we can look at what may happen if different scenarios unfold.\n\n# **Other Limitations and Areas for Improvement**\n\nThough I followed guidance from the Kansas Essential Functions Framework, the designation of occupations as essential is somewhat subjective. It might be nice to have others weigh in on which occupations meet the conditions of these guidelines.\n\nAlso, I started working on adding a field that indicates which positions may be performed from home (we would be able to subtract these from the unemployed as well), but this is also very subjective. I thought O\\*NET might also have some sort of \"telecommute score,\" but I haven't been able to find anything like that just yet.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","embed-resources":true,"toc":false,"css":["../styles.css"],"output-file":"Unemployment.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.309","page-layout":"full","footer":"footer.html","author":"Nigel Soria","badges":true,"categories":["labor statistics","unemployment rate","essential worker","work context"],"permalink":"/unemployment-calc/","image":"images/ks-unemp.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}